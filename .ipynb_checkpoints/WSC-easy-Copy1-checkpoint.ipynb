{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bd4f8a0",
   "metadata": {},
   "source": [
    "# Winograd Schema Challenge for Spanish "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1de23e",
   "metadata": {},
   "source": [
    "TO DO\n",
    "- Data prep:\n",
    "    - create sentences\n",
    "    - keep correct pronoun\n",
    "    - separate train/test?\n",
    "- LM\n",
    "    - create LSTM or use BERT?\n",
    "    - calculate prob per sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e54c27fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext\n",
      "  Downloading torchtext-0.11.0-cp39-cp39-manylinux1_x86_64.whl (8.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.0 MB 4.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/site-packages (from torchtext) (4.62.0)\n",
      "Requirement already satisfied: requests in /usr/lib/python3.9/site-packages (from torchtext) (2.25.1)\n",
      "Collecting torch==1.10.0\n",
      "  Downloading torch-1.10.0-cp39-cp39-manylinux1_x86_64.whl (881.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 881.9 MB 590 bytes/s a 0:00:01    |█                               | 29.9 MB 14.7 MB/s eta 0:00:58\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib64/python3.9/site-packages (from torchtext) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/site-packages (from torch==1.10.0->torchtext) (3.7.4.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3.9/site-packages (from requests->torchtext) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/lib/python3.9/site-packages (from requests->torchtext) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3.9/site-packages (from requests->torchtext) (1.25.10)\n",
      "Installing collected packages: torch, torchtext\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.10.0+cu111 requires torch==1.9.0, but you have torch 1.10.0 which is incompatible.\n",
      "torchaudio 0.9.0 requires torch==1.9.0, but you have torch 1.10.0 which is incompatible.\u001b[0m\n",
      "Successfully installed torch-1.10.0 torchtext-0.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --user torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ea34969",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchtext.legacy.data import Field, BucketIterator, TabularDataset\n",
    "\n",
    "# torchtext.legacy.data.Field\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c08dc802",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04ceedb",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c448df",
   "metadata": {},
   "source": [
    "### Preparing Wikicorpus sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97ee76a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dc483f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "# sent_tokenize(s)\n",
    "\n",
    "f = open('data/prova.txt', 'r')\n",
    "l = f.readlines()\n",
    "f.close()\n",
    "\n",
    "endtokens = '.?!:'\n",
    "\n",
    "g = open('sentences.csv', 'w')\n",
    "s = ''\n",
    "for line in l:\n",
    "    if line[-2] in endtokens:\n",
    "        s += line[:-1] + '\\n'\n",
    "        g.write(s)\n",
    "        s = ''\n",
    "    else:\n",
    "        s+= line[:-1]\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d80f92",
   "metadata": {},
   "source": [
    "Run processing_wiki_data.py to get \"wiki_sentences.txt\". It contains X sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dad84e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(wiki_path):\n",
    "    whitespacer = lambda x: x.split(' ')\n",
    "    \n",
    "    WORDS = Field(tokenize    = whitespacer,\n",
    "                lower       = True,\n",
    "                batch_first = True,\n",
    "                init_token='<start>',\n",
    "                eos_token='<end>') \n",
    "    \n",
    "    # read the csv file\n",
    "    wikipedia = TabularDataset(path = wiki_path, # wiki_sent.csv\n",
    "                            format = 'csv',\n",
    "                            fields = [('sentence', WORDS)],\n",
    "                            skip_header       = True,\n",
    "                            csv_reader_params = {'quotechar':'Ö'}) \n",
    "    \n",
    "    # build vocabularies based on what our csv files contained and create word2id mapping\n",
    "    WORDS.build_vocab(wikipedia)\n",
    "\n",
    "    # create batches from our data, and shuffle them for each epoch\n",
    "    wikipedia_iter = BucketIterator(wikipedia,\n",
    "                                  batch_size        = 8,\n",
    "                                  sort_within_batch = True,\n",
    "                                  sort_key          = lambda x: len(x.sentence),\n",
    "                                  shuffle           = True,\n",
    "                                  device            = device)\n",
    "\n",
    "    return wikipedia_iter, WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8587efd",
   "metadata": {},
   "source": [
    "### Preparing WCS sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f756d471",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_un = '/home/gusgraupa@GU.GU.SE/MLNLP2/LT2326-Project/data/Dataset_with_pn_undescores_det.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cd9801d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_creation(filename):\n",
    "    f = open(filename, 'r')\n",
    "    l = f.readlines()\n",
    "    \n",
    "    grouped = []\n",
    "    j = []\n",
    "    for e in l:\n",
    "        if e == '\\n':\n",
    "            grouped.append(j)\n",
    "            j = []\n",
    "        else:\n",
    "            j.append(e[:-1])\n",
    "            \n",
    "    sentences = []\n",
    "    \n",
    "    for group in grouped:\n",
    "        \n",
    "        if group[1] == 'su' or group[1] == 'sus':\n",
    "            sentence = group[0][:-1]\n",
    "            words = sentence.split()\n",
    "            for i, w in enumerate(words):\n",
    "                if w == '_' + group[1] + '_': \n",
    "                    words.remove(w)\n",
    "                    words_copy = words.copy()\n",
    "                    words.insert(i+1, 'de ' + group[2])\n",
    "                    words_copy.insert(i+1, 'de ' + group[3])\n",
    "                    \n",
    "                    s1 = ' '.join(words) + '.'\n",
    "                    s2 = ' '.join(words_copy) + '.'\n",
    "                    \n",
    "                    g1 = (s1.lower(), group[2] == group[4])\n",
    "                    g2 = (s2.lower(), group[3] == group[4])\n",
    "        \n",
    "        else:\n",
    "            check = '_' + group[1] + '_'\n",
    "            \n",
    "            s1 = group[0].replace(check, group[2])\n",
    "            s2 = group[0].replace(check, group[3])\n",
    "            \n",
    "            g1 = (s1.lower(), group[2] == group[4])\n",
    "            g2 = (s2.lower(), group[3] == group[4])\n",
    "        sentences.append((g1, g2))\n",
    "        \n",
    "    f.close()\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acf3e668",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('los concejales de la ciudad denegaron el permiso a los manifestantes porque los concejales de la ciudad temían la violencia.',\n",
       "  True),\n",
       " ('los concejales de la ciudad denegaron el permiso a los manifestantes porque los manifestantes temían la violencia.',\n",
       "  False))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = sentence_creation(data_un)\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f71cf1f",
   "metadata": {},
   "source": [
    "## Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97b095c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "batch_size = 2\n",
    "learning_rate = 0.001\n",
    "embedding_size = 256\n",
    "hidden_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aebca317",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, vocab_len, embedding_size, hidden_size):\n",
    "\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.vocab_len = vocab_len\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_len, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size//2)\n",
    "        self.fc2 = nn.Linear(hidden_size//2, vocab_len)\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        embeds = self.embedding(x)\n",
    "        out, hidden = self.lstm(embeds)\n",
    "        fc1_out = self.fc1(out)\n",
    "        fc2_out = self.fc2(fc1_out)\n",
    "        output = self.softmax(fc2_out)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5d9f70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training function\n",
    "\n",
    "def train(path, epochs, batch_size, learning_rate, embedding_size, hidden_size, device):\n",
    "    \n",
    "    # loading the data\n",
    "    dataset, vocab = get_data(path)\n",
    "    \n",
    "    model = LSTM(len(vocab.vocab), embedding_size, hidden_size)\n",
    "    model.to(device)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # start training loop\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        for i, batch in enumerate(dataset):\n",
    "\n",
    "            # the strucure for each BATCH is:\n",
    "            # <start>, w0, ..., wn, <end>\n",
    "            sentence = batch.sentence\n",
    "\n",
    "            # we do not want to give <end> as input to the model\n",
    "            input_sentence = sentence[:, :-1]\n",
    "\n",
    "            # send to model\n",
    "            output = model(input_sentence)\n",
    "\n",
    "            # we select all but the first token from sentences\n",
    "            target = sentence[:, 1:]\n",
    "            \n",
    "#             print(output.size()) 8, 11, 360000\n",
    "#             print(target.size()) 8, 11\n",
    "            \n",
    "            loss = loss_fn(output.permute(0, 2, 1), target)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # print average loss for the epoch\n",
    "            print(total_loss/(i+1), end='\\r') \n",
    "\n",
    "            # compute gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # update parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # reset gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        print()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dcffac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.2722037694549565\n",
      "13.598793445682526\n",
      "19.459904922142038\n",
      "24.917827505397796\n",
      "30.003621889743805\n"
     ]
    }
   ],
   "source": [
    "# with mini_wiki_sent.csv\n",
    "\n",
    "model_mini = train('mini_wiki_sent.csv', epochs, batch_size, learning_rate, embedding_size, hidden_size, device)\n",
    "\n",
    "# saving the model\n",
    "torch.save(model, 'mini_lstm_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c216d97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.4633059020423895\n",
      "14.158298510017396\n",
      "20.546251615085602\n",
      "26.662729534435277\n",
      "32.530420682411295\n"
     ]
    }
   ],
   "source": [
    "# with medium_wiki_sent.csv\n",
    "model_medium = train('medium_wiki_sent.csv', epochs, batch_size, learning_rate, embedding_size, hidden_size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "583586f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model\n",
    "torch.save(model_medium, 'lstm_model_medium.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce49b5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b02929d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.6702164727208035\r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.82 GiB (GPU 3; 10.92 GiB total capacity; 8.82 GiB already allocated; 458.38 MiB free; 8.84 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1915416/1573633841.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# with new_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_book\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sentences.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1915416/2549079278.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(path, epochs, batch_size, learning_rate, embedding_size, hidden_size, device)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m#             print(target.size()) 8, 11\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1151\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m                                label_smoothing=self.label_smoothing)\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2844\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2846\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.82 GiB (GPU 3; 10.92 GiB total capacity; 8.82 GiB already allocated; 458.38 MiB free; 8.84 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# with new_dataset\n",
    "model_book = train('sentences.csv', epochs, batch_size, learning_rate, embedding_size, hidden_size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dd28dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model\n",
    "torch.save(model_book, 'lstm_model_book.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14b36c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_medium = torch.load('lstm_model_medium.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93fa8e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, vocab = get_data('medium_wiki_sent.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "307c3922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (embedding): Embedding(122593, 256)\n",
       "  (lstm): LSTM(256, 128, batch_first=True)\n",
       "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=122593, bias=True)\n",
       "  (softmax): LogSoftmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_medium.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42a4ee5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, vocab = get_data('usable_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bdf26db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, vocab = get_data('sentences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48e01491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61781"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fdaad8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191273"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e34e360a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109829"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68da80ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1136, 0.0879, 0.1016, 0.0928, 0.0709, 0.0689, 0.0643, 0.1664, 0.1408,\n",
       "        0.0930])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand(10)\n",
    "ts = F.softmax(t, dim=0)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ab5dc59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1664)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3587dc96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8401, 0.4189, 0.7460, 0.2897, 0.0427, 0.0213, 0.3599, 0.6085,\n",
       "          0.1460, 0.2513],\n",
       "         [0.4996, 0.6992, 0.2462, 0.3649, 0.7476, 0.2809, 0.4466, 0.8648,\n",
       "          0.9327, 0.2741]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = torch.rand(1, 2, 10)\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec5da951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1538, 0.1009, 0.1400, 0.0887, 0.0693, 0.0678, 0.0952, 0.1220,\n",
       "          0.0768, 0.0854],\n",
       "         [0.0936, 0.1143, 0.0726, 0.0818, 0.1199, 0.0752, 0.0888, 0.1348,\n",
       "          0.1443, 0.0747]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts2 = F.softmax(t2, dim=2)\n",
    "ts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fc006863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1538, 0.1443]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.max(ts2, dim=2)\n",
    "a.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a3541f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2981)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(a.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d5b75b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getting_prob(sentences, vocab, model):\n",
    "    probs = []\n",
    "    n = 0\n",
    "    tot = 0\n",
    "    \n",
    "    for sent in sentences: # ((Sent1, True), (Sent2, False))\n",
    "        tot += 1\n",
    "        for pair in sent:\n",
    "            if pair[1]:\n",
    "                true_sent = pair[0]\n",
    "            else:\n",
    "                false_sent = pair[0]\n",
    "\n",
    "        # tokenizing sent\n",
    "        tok_true_sent = true_sent.split()\n",
    "        tok_false_sent = false_sent.split()\n",
    "\n",
    "        # encoding\n",
    "        enc_true_sent = torch.tensor([vocab.vocab.stoi[x] for x in tok_true_sent], device=device)\n",
    "        enc_false_sent = torch.tensor([vocab.vocab.stoi[x] for x in tok_false_sent], device=device)\n",
    "\n",
    "        # model\n",
    "#         out_true_sent = model(enc_true_sent[:len(enc_true_sent)-1].unsqueeze(0))\n",
    "#         out_false_sent = model(enc_false_sent[:len(enc_false_sent)-1].unsqueeze(0)\n",
    "        out_true_sent = model(enc_true_sent.unsqueeze(0))\n",
    "        out_false_sent = model(enc_false_sent.unsqueeze(0))\n",
    "#         print(out_true_sent.size())\n",
    "\n",
    "        # get probabilities \n",
    "        true_prob = F.softmax(out_true_sent, dim=2)\n",
    "        false_prob = F.softmax(out_false_sent, dim=2)\n",
    "\n",
    "        # append\n",
    "        true_max = torch.max(true_prob, dim=2)\n",
    "        false_max = torch.max(false_prob, dim=2)\n",
    "        \n",
    "        true_sent_prob = torch.sum(true_max.values)\n",
    "        false_sent_prob = torch.sum(false_max.values)\n",
    "        \n",
    "        probs.append((true_sent_prob, false_sent_prob))\n",
    "        n += int(true_sent_prob > false_sent_prob)\n",
    "        \n",
    "#         probs.append((true_prob[0,0,:].sum(), false_prob[0,0,:].sum()))\n",
    "#         n += int(true_prob[0,0,:].sum()>false_prob[0,0,:].sum())\n",
    "    \n",
    "    print('Higher prob of correct cases in:', n/tot)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "da1a1796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher prob of correct cases in: 0.4111111111111111\n"
     ]
    }
   ],
   "source": [
    "probs = getting_prob(sentences, vocab, model_medium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f07476dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor(6.8502, grad_fn=<SumBackward0>),\n",
       "  tensor(5.6651, grad_fn=<SumBackward0>)),\n",
       " (tensor(6.3412, grad_fn=<SumBackward0>),\n",
       "  tensor(7.4655, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.0114, grad_fn=<SumBackward0>),\n",
       "  tensor(4.4789, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.4789, grad_fn=<SumBackward0>),\n",
       "  tensor(4.0114, grad_fn=<SumBackward0>)),\n",
       " (tensor(2.8121, grad_fn=<SumBackward0>),\n",
       "  tensor(2.9396, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.1061, grad_fn=<SumBackward0>),\n",
       "  tensor(3.0802, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.7711, grad_fn=<SumBackward0>),\n",
       "  tensor(3.4839, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.4839, grad_fn=<SumBackward0>),\n",
       "  tensor(3.7711, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.0724, grad_fn=<SumBackward0>),\n",
       "  tensor(3.9941, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.9941, grad_fn=<SumBackward0>),\n",
       "  tensor(4.0724, grad_fn=<SumBackward0>)),\n",
       " (tensor(6.2339, grad_fn=<SumBackward0>),\n",
       "  tensor(4.9421, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.9421, grad_fn=<SumBackward0>),\n",
       "  tensor(6.2339, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.4992, grad_fn=<SumBackward0>),\n",
       "  tensor(4.5066, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.6346, grad_fn=<SumBackward0>),\n",
       "  tensor(4.6283, grad_fn=<SumBackward0>)),\n",
       " (tensor(1.9208, grad_fn=<SumBackward0>),\n",
       "  tensor(1.3289, grad_fn=<SumBackward0>)),\n",
       " (tensor(1.3289, grad_fn=<SumBackward0>),\n",
       "  tensor(1.9208, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.4054, grad_fn=<SumBackward0>),\n",
       "  tensor(2.5439, grad_fn=<SumBackward0>)),\n",
       " (tensor(2.5439, grad_fn=<SumBackward0>),\n",
       "  tensor(3.4054, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.9049, grad_fn=<SumBackward0>),\n",
       "  tensor(4.1659, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.1659, grad_fn=<SumBackward0>),\n",
       "  tensor(3.9049, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.3399, grad_fn=<SumBackward0>),\n",
       "  tensor(3.3399, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.4751, grad_fn=<SumBackward0>),\n",
       "  tensor(3.9722, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.4250, grad_fn=<SumBackward0>),\n",
       "  tensor(3.3011, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.9997, grad_fn=<SumBackward0>),\n",
       "  tensor(4.2319, grad_fn=<SumBackward0>)),\n",
       " (tensor(2.5143, grad_fn=<SumBackward0>),\n",
       "  tensor(1.4694, grad_fn=<SumBackward0>)),\n",
       " (tensor(1.4694, grad_fn=<SumBackward0>),\n",
       "  tensor(2.5143, grad_fn=<SumBackward0>)),\n",
       " (tensor(5.0237, grad_fn=<SumBackward0>),\n",
       "  tensor(4.9848, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.9848, grad_fn=<SumBackward0>),\n",
       "  tensor(5.0237, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.8562, grad_fn=<SumBackward0>),\n",
       "  tensor(4.5664, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.9106, grad_fn=<SumBackward0>),\n",
       "  tensor(5.1896, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.1440, grad_fn=<SumBackward0>),\n",
       "  tensor(4.2536, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.5358, grad_fn=<SumBackward0>),\n",
       "  tensor(3.4036, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.8667, grad_fn=<SumBackward0>),\n",
       "  tensor(4.4376, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.4910, grad_fn=<SumBackward0>),\n",
       "  tensor(3.8527, grad_fn=<SumBackward0>)),\n",
       " (tensor(1.8590, grad_fn=<SumBackward0>),\n",
       "  tensor(1.8590, grad_fn=<SumBackward0>)),\n",
       " (tensor(2.1024, grad_fn=<SumBackward0>),\n",
       "  tensor(2.5033, grad_fn=<SumBackward0>)),\n",
       " (tensor(5.8622, grad_fn=<SumBackward0>),\n",
       "  tensor(5.2310, grad_fn=<SumBackward0>)),\n",
       " (tensor(5.6071, grad_fn=<SumBackward0>),\n",
       "  tensor(6.2338, grad_fn=<SumBackward0>)),\n",
       " (tensor(1.0861, grad_fn=<SumBackward0>),\n",
       "  tensor(1.0861, grad_fn=<SumBackward0>)),\n",
       " (tensor(0.9752, grad_fn=<SumBackward0>),\n",
       "  tensor(0.9752, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.2183, grad_fn=<SumBackward0>),\n",
       "  tensor(4.0527, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.0527, grad_fn=<SumBackward0>),\n",
       "  tensor(4.2183, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.3403, grad_fn=<SumBackward0>),\n",
       "  tensor(3.4148, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.4148, grad_fn=<SumBackward0>),\n",
       "  tensor(4.3403, grad_fn=<SumBackward0>)),\n",
       " (tensor(2.8268, grad_fn=<SumBackward0>),\n",
       "  tensor(3.1655, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.1655, grad_fn=<SumBackward0>),\n",
       "  tensor(2.8268, grad_fn=<SumBackward0>)),\n",
       " (tensor(2.7875, grad_fn=<SumBackward0>),\n",
       "  tensor(3.1024, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.1024, grad_fn=<SumBackward0>),\n",
       "  tensor(2.7875, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.3169, grad_fn=<SumBackward0>),\n",
       "  tensor(4.4659, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.5563, grad_fn=<SumBackward0>),\n",
       "  tensor(4.2992, grad_fn=<SumBackward0>)),\n",
       " (tensor(6.2352, grad_fn=<SumBackward0>),\n",
       "  tensor(6.7577, grad_fn=<SumBackward0>)),\n",
       " (tensor(6.7577, grad_fn=<SumBackward0>),\n",
       "  tensor(6.2352, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.9603, grad_fn=<SumBackward0>),\n",
       "  tensor(3.6417, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.5528, grad_fn=<SumBackward0>),\n",
       "  tensor(3.7850, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.3156, grad_fn=<SumBackward0>),\n",
       "  tensor(3.3156, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.5017, grad_fn=<SumBackward0>),\n",
       "  tensor(4.5017, grad_fn=<SumBackward0>)),\n",
       " (tensor(2.2005, grad_fn=<SumBackward0>),\n",
       "  tensor(2.2005, grad_fn=<SumBackward0>)),\n",
       " (tensor(2.2005, grad_fn=<SumBackward0>),\n",
       "  tensor(2.2005, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.6737, grad_fn=<SumBackward0>),\n",
       "  tensor(4.7352, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.7352, grad_fn=<SumBackward0>),\n",
       "  tensor(4.6737, grad_fn=<SumBackward0>)),\n",
       " (tensor(5.1130, grad_fn=<SumBackward0>),\n",
       "  tensor(5.1130, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.9009, grad_fn=<SumBackward0>),\n",
       "  tensor(3.9009, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.9009, grad_fn=<SumBackward0>),\n",
       "  tensor(5.8932, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.7845, grad_fn=<SumBackward0>),\n",
       "  tensor(6.0226, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.9765, grad_fn=<SumBackward0>),\n",
       "  tensor(3.5272, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.0785, grad_fn=<SumBackward0>),\n",
       "  tensor(4.8821, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.8697, grad_fn=<SumBackward0>),\n",
       "  tensor(4.2042, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.0615, grad_fn=<SumBackward0>),\n",
       "  tensor(3.6908, grad_fn=<SumBackward0>)),\n",
       " (tensor(5.4441, grad_fn=<SumBackward0>),\n",
       "  tensor(3.7409, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.7409, grad_fn=<SumBackward0>),\n",
       "  tensor(5.4441, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.1607, grad_fn=<SumBackward0>),\n",
       "  tensor(4.1607, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.3978, grad_fn=<SumBackward0>),\n",
       "  tensor(3.3978, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.8309, grad_fn=<SumBackward0>),\n",
       "  tensor(4.3484, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.3484, grad_fn=<SumBackward0>),\n",
       "  tensor(4.8309, grad_fn=<SumBackward0>)),\n",
       " (tensor(1.9927, grad_fn=<SumBackward0>),\n",
       "  tensor(2.1233, grad_fn=<SumBackward0>)),\n",
       " (tensor(2.1233, grad_fn=<SumBackward0>),\n",
       "  tensor(1.9927, grad_fn=<SumBackward0>)),\n",
       " (tensor(6.2455, grad_fn=<SumBackward0>),\n",
       "  tensor(5.9724, grad_fn=<SumBackward0>)),\n",
       " (tensor(5.9724, grad_fn=<SumBackward0>),\n",
       "  tensor(6.2455, grad_fn=<SumBackward0>)),\n",
       " (tensor(7.8699, grad_fn=<SumBackward0>),\n",
       "  tensor(7.6712, grad_fn=<SumBackward0>)),\n",
       " (tensor(7.6712, grad_fn=<SumBackward0>),\n",
       "  tensor(7.8699, grad_fn=<SumBackward0>)),\n",
       " (tensor(8.8465, grad_fn=<SumBackward0>),\n",
       "  tensor(8.8484, grad_fn=<SumBackward0>)),\n",
       " (tensor(7.8378, grad_fn=<SumBackward0>),\n",
       "  tensor(7.9316, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.1688, grad_fn=<SumBackward0>),\n",
       "  tensor(4.1188, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.8475, grad_fn=<SumBackward0>),\n",
       "  tensor(5.0656, grad_fn=<SumBackward0>)),\n",
       " (tensor(7.0803, grad_fn=<SumBackward0>),\n",
       "  tensor(7.3119, grad_fn=<SumBackward0>)),\n",
       " (tensor(7.3119, grad_fn=<SumBackward0>),\n",
       "  tensor(7.0803, grad_fn=<SumBackward0>)),\n",
       " (tensor(5.3210, grad_fn=<SumBackward0>),\n",
       "  tensor(4.3002, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.3002, grad_fn=<SumBackward0>),\n",
       "  tensor(5.3210, grad_fn=<SumBackward0>)),\n",
       " (tensor(1.7316, grad_fn=<SumBackward0>),\n",
       "  tensor(1.9578, grad_fn=<SumBackward0>)),\n",
       " (tensor(1.7316, grad_fn=<SumBackward0>),\n",
       "  tensor(2.1965, grad_fn=<SumBackward0>)),\n",
       " (tensor(6.3534, grad_fn=<SumBackward0>),\n",
       "  tensor(5.8809, grad_fn=<SumBackward0>)),\n",
       " (tensor(5.8809, grad_fn=<SumBackward0>),\n",
       "  tensor(6.3534, grad_fn=<SumBackward0>)),\n",
       " (tensor(8.3588, grad_fn=<SumBackward0>),\n",
       "  tensor(10.3939, grad_fn=<SumBackward0>)),\n",
       " (tensor(10.3939, grad_fn=<SumBackward0>),\n",
       "  tensor(8.3588, grad_fn=<SumBackward0>)),\n",
       " (tensor(2.2214, grad_fn=<SumBackward0>),\n",
       "  tensor(2.0658, grad_fn=<SumBackward0>)),\n",
       " (tensor(2.0658, grad_fn=<SumBackward0>),\n",
       "  tensor(2.2214, grad_fn=<SumBackward0>)),\n",
       " (tensor(6.4164, grad_fn=<SumBackward0>),\n",
       "  tensor(8.2056, grad_fn=<SumBackward0>)),\n",
       " (tensor(8.2056, grad_fn=<SumBackward0>),\n",
       "  tensor(6.4164, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.5313, grad_fn=<SumBackward0>),\n",
       "  tensor(4.4693, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.9579, grad_fn=<SumBackward0>),\n",
       "  tensor(4.0689, grad_fn=<SumBackward0>)),\n",
       " (tensor(5.7675, grad_fn=<SumBackward0>),\n",
       "  tensor(5.7675, grad_fn=<SumBackward0>)),\n",
       " (tensor(5.7675, grad_fn=<SumBackward0>),\n",
       "  tensor(5.7675, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.0577, grad_fn=<SumBackward0>),\n",
       "  tensor(4.7020, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.6967, grad_fn=<SumBackward0>),\n",
       "  tensor(3.9652, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.7689, grad_fn=<SumBackward0>),\n",
       "  tensor(3.8040, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.9037, grad_fn=<SumBackward0>),\n",
       "  tensor(3.6039, grad_fn=<SumBackward0>)),\n",
       " (tensor(5.3947, grad_fn=<SumBackward0>),\n",
       "  tensor(5.2184, grad_fn=<SumBackward0>)),\n",
       " (tensor(5.2184, grad_fn=<SumBackward0>),\n",
       "  tensor(5.3947, grad_fn=<SumBackward0>)),\n",
       " (tensor(6.1837, grad_fn=<SumBackward0>),\n",
       "  tensor(5.9371, grad_fn=<SumBackward0>)),\n",
       " (tensor(5.9371, grad_fn=<SumBackward0>),\n",
       "  tensor(6.1837, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.6429, grad_fn=<SumBackward0>),\n",
       "  tensor(5.2828, grad_fn=<SumBackward0>)),\n",
       " (tensor(5.2828, grad_fn=<SumBackward0>),\n",
       "  tensor(4.6429, grad_fn=<SumBackward0>)),\n",
       " (tensor(7.2427, grad_fn=<SumBackward0>),\n",
       "  tensor(7.1075, grad_fn=<SumBackward0>)),\n",
       " (tensor(7.1075, grad_fn=<SumBackward0>),\n",
       "  tensor(7.2427, grad_fn=<SumBackward0>)),\n",
       " (tensor(5.0862, grad_fn=<SumBackward0>),\n",
       "  tensor(4.6032, grad_fn=<SumBackward0>)),\n",
       " (tensor(5.0862, grad_fn=<SumBackward0>),\n",
       "  tensor(4.6463, grad_fn=<SumBackward0>)),\n",
       " (tensor(6.5281, grad_fn=<SumBackward0>),\n",
       "  tensor(7.0843, grad_fn=<SumBackward0>)),\n",
       " (tensor(7.0843, grad_fn=<SumBackward0>),\n",
       "  tensor(6.5281, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.4689, grad_fn=<SumBackward0>),\n",
       "  tensor(4.8602, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.9131, grad_fn=<SumBackward0>),\n",
       "  tensor(4.5586, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.2761, grad_fn=<SumBackward0>),\n",
       "  tensor(3.4236, grad_fn=<SumBackward0>)),\n",
       " (tensor(2.5827, grad_fn=<SumBackward0>),\n",
       "  tensor(2.7279, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.9268, grad_fn=<SumBackward0>),\n",
       "  tensor(4.0863, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.5329, grad_fn=<SumBackward0>),\n",
       "  tensor(3.3868, grad_fn=<SumBackward0>)),\n",
       " (tensor(7.1177, grad_fn=<SumBackward0>),\n",
       "  tensor(7.0251, grad_fn=<SumBackward0>)),\n",
       " (tensor(7.0251, grad_fn=<SumBackward0>),\n",
       "  tensor(7.1177, grad_fn=<SumBackward0>)),\n",
       " (tensor(6.4660, grad_fn=<SumBackward0>),\n",
       "  tensor(6.0588, grad_fn=<SumBackward0>)),\n",
       " (tensor(6.3194, grad_fn=<SumBackward0>),\n",
       "  tensor(6.6481, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.2819, grad_fn=<SumBackward0>),\n",
       "  tensor(2.9931, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.5264, grad_fn=<SumBackward0>),\n",
       "  tensor(3.3852, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.2645, grad_fn=<SumBackward0>),\n",
       "  tensor(3.2043, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.2043, grad_fn=<SumBackward0>),\n",
       "  tensor(3.2645, grad_fn=<SumBackward0>)),\n",
       " (tensor(2.7632, grad_fn=<SumBackward0>),\n",
       "  tensor(2.7019, grad_fn=<SumBackward0>)),\n",
       " (tensor(2.7019, grad_fn=<SumBackward0>),\n",
       "  tensor(2.7632, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.3107, grad_fn=<SumBackward0>),\n",
       "  tensor(3.3107, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.3107, grad_fn=<SumBackward0>),\n",
       "  tensor(3.3107, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.3107, grad_fn=<SumBackward0>),\n",
       "  tensor(7.0730, grad_fn=<SumBackward0>)),\n",
       " (tensor(6.8607, grad_fn=<SumBackward0>),\n",
       "  tensor(6.9117, grad_fn=<SumBackward0>)),\n",
       " (tensor(6.6758, grad_fn=<SumBackward0>),\n",
       "  tensor(7.0549, grad_fn=<SumBackward0>)),\n",
       " (tensor(6.9187, grad_fn=<SumBackward0>),\n",
       "  tensor(6.6169, grad_fn=<SumBackward0>)),\n",
       " (tensor(5.8309, grad_fn=<SumBackward0>),\n",
       "  tensor(6.4870, grad_fn=<SumBackward0>)),\n",
       " (tensor(6.4870, grad_fn=<SumBackward0>),\n",
       "  tensor(5.8309, grad_fn=<SumBackward0>)),\n",
       " (tensor(2.2137, grad_fn=<SumBackward0>),\n",
       "  tensor(2.5480, grad_fn=<SumBackward0>)),\n",
       " (tensor(2.5480, grad_fn=<SumBackward0>),\n",
       "  tensor(2.2137, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.2420, grad_fn=<SumBackward0>),\n",
       "  tensor(4.6300, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.3045, grad_fn=<SumBackward0>),\n",
       "  tensor(4.3595, grad_fn=<SumBackward0>)),\n",
       " (tensor(6.1329, grad_fn=<SumBackward0>),\n",
       "  tensor(4.8791, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.9038, grad_fn=<SumBackward0>),\n",
       "  tensor(6.1438, grad_fn=<SumBackward0>)),\n",
       " (tensor(2.6743, grad_fn=<SumBackward0>),\n",
       "  tensor(3.5045, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.5045, grad_fn=<SumBackward0>),\n",
       "  tensor(2.6743, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.1642, grad_fn=<SumBackward0>),\n",
       "  tensor(3.9663, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.9663, grad_fn=<SumBackward0>),\n",
       "  tensor(4.1642, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.0404, grad_fn=<SumBackward0>),\n",
       "  tensor(3.0404, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.4095, grad_fn=<SumBackward0>),\n",
       "  tensor(3.4095, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.7356, grad_fn=<SumBackward0>),\n",
       "  tensor(3.8766, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.6079, grad_fn=<SumBackward0>),\n",
       "  tensor(3.5797, grad_fn=<SumBackward0>)),\n",
       " (tensor(5.4130, grad_fn=<SumBackward0>),\n",
       "  tensor(4.9688, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.4842, grad_fn=<SumBackward0>),\n",
       "  tensor(5.4130, grad_fn=<SumBackward0>)),\n",
       " (tensor(6.3480, grad_fn=<SumBackward0>),\n",
       "  tensor(5.4015, grad_fn=<SumBackward0>)),\n",
       " (tensor(5.4015, grad_fn=<SumBackward0>),\n",
       "  tensor(6.3480, grad_fn=<SumBackward0>)),\n",
       " (tensor(5.6254, grad_fn=<SumBackward0>),\n",
       "  tensor(5.3400, grad_fn=<SumBackward0>)),\n",
       " (tensor(6.0880, grad_fn=<SumBackward0>),\n",
       "  tensor(6.2291, grad_fn=<SumBackward0>)),\n",
       " (tensor(6.0880, grad_fn=<SumBackward0>),\n",
       "  tensor(10.3759, grad_fn=<SumBackward0>)),\n",
       " (tensor(8.2668, grad_fn=<SumBackward0>),\n",
       "  tensor(7.8219, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.3178, grad_fn=<SumBackward0>),\n",
       "  tensor(3.8428, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.6170, grad_fn=<SumBackward0>),\n",
       "  tensor(4.1132, grad_fn=<SumBackward0>)),\n",
       " (tensor(9.9465, grad_fn=<SumBackward0>),\n",
       "  tensor(10.0673, grad_fn=<SumBackward0>)),\n",
       " (tensor(10.0673, grad_fn=<SumBackward0>),\n",
       "  tensor(9.9465, grad_fn=<SumBackward0>)),\n",
       " (tensor(7.6859, grad_fn=<SumBackward0>),\n",
       "  tensor(7.2044, grad_fn=<SumBackward0>)),\n",
       " (tensor(7.4883, grad_fn=<SumBackward0>),\n",
       "  tensor(7.9322, grad_fn=<SumBackward0>)),\n",
       " (tensor(6.0664, grad_fn=<SumBackward0>),\n",
       "  tensor(5.6556, grad_fn=<SumBackward0>)),\n",
       " (tensor(5.6556, grad_fn=<SumBackward0>),\n",
       "  tensor(6.0664, grad_fn=<SumBackward0>)),\n",
       " (tensor(8.0103, grad_fn=<SumBackward0>),\n",
       "  tensor(9.0709, grad_fn=<SumBackward0>)),\n",
       " (tensor(9.1400, grad_fn=<SumBackward0>),\n",
       "  tensor(8.2192, grad_fn=<SumBackward0>)),\n",
       " (tensor(5.9588, grad_fn=<SumBackward0>),\n",
       "  tensor(5.6907, grad_fn=<SumBackward0>)),\n",
       " (tensor(5.8769, grad_fn=<SumBackward0>),\n",
       "  tensor(5.6999, grad_fn=<SumBackward0>)),\n",
       " (tensor(6.5309, grad_fn=<SumBackward0>),\n",
       "  tensor(5.8630, grad_fn=<SumBackward0>)),\n",
       " (tensor(5.8630, grad_fn=<SumBackward0>),\n",
       "  tensor(6.5309, grad_fn=<SumBackward0>)),\n",
       " (tensor(5.9990, grad_fn=<SumBackward0>),\n",
       "  tensor(5.7362, grad_fn=<SumBackward0>)),\n",
       " (tensor(5.4575, grad_fn=<SumBackward0>),\n",
       "  tensor(5.4552, grad_fn=<SumBackward0>)),\n",
       " (tensor(1.7478, grad_fn=<SumBackward0>),\n",
       "  tensor(2.1425, grad_fn=<SumBackward0>)),\n",
       " (tensor(1.5469, grad_fn=<SumBackward0>),\n",
       "  tensor(1.6148, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.3400, grad_fn=<SumBackward0>),\n",
       "  tensor(4.6508, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.9767, grad_fn=<SumBackward0>),\n",
       "  tensor(3.7081, grad_fn=<SumBackward0>)),\n",
       " (tensor(9.8196, grad_fn=<SumBackward0>),\n",
       "  tensor(9.3681, grad_fn=<SumBackward0>)),\n",
       " (tensor(9.3681, grad_fn=<SumBackward0>),\n",
       "  tensor(9.8196, grad_fn=<SumBackward0>)),\n",
       " (tensor(8.4097, grad_fn=<SumBackward0>),\n",
       "  tensor(9.0127, grad_fn=<SumBackward0>)),\n",
       " (tensor(8.7077, grad_fn=<SumBackward0>),\n",
       "  tensor(8.0622, grad_fn=<SumBackward0>)),\n",
       " (tensor(6.7755, grad_fn=<SumBackward0>),\n",
       "  tensor(6.1110, grad_fn=<SumBackward0>)),\n",
       " (tensor(5.6766, grad_fn=<SumBackward0>),\n",
       "  tensor(6.3401, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.5477, grad_fn=<SumBackward0>),\n",
       "  tensor(4.5477, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.5806, grad_fn=<SumBackward0>),\n",
       "  tensor(3.5806, grad_fn=<SumBackward0>)),\n",
       " (tensor(6.3487, grad_fn=<SumBackward0>),\n",
       "  tensor(6.3487, grad_fn=<SumBackward0>)),\n",
       " (tensor(6.3487, grad_fn=<SumBackward0>),\n",
       "  tensor(6.3487, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.8879, grad_fn=<SumBackward0>),\n",
       "  tensor(5.1057, grad_fn=<SumBackward0>)),\n",
       " (tensor(5.0993, grad_fn=<SumBackward0>),\n",
       "  tensor(5.0332, grad_fn=<SumBackward0>)),\n",
       " (tensor(2.3112, grad_fn=<SumBackward0>),\n",
       "  tensor(2.0900, grad_fn=<SumBackward0>)),\n",
       " (tensor(2.0900, grad_fn=<SumBackward0>),\n",
       "  tensor(2.3112, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.7720, grad_fn=<SumBackward0>),\n",
       "  tensor(4.7720, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.7720, grad_fn=<SumBackward0>),\n",
       "  tensor(4.7720, grad_fn=<SumBackward0>)),\n",
       " (tensor(7.6322, grad_fn=<SumBackward0>),\n",
       "  tensor(6.9523, grad_fn=<SumBackward0>)),\n",
       " (tensor(6.0616, grad_fn=<SumBackward0>),\n",
       "  tensor(6.3934, grad_fn=<SumBackward0>)),\n",
       " (tensor(1.7265, grad_fn=<SumBackward0>),\n",
       "  tensor(1.6657, grad_fn=<SumBackward0>)),\n",
       " (tensor(1.9117, grad_fn=<SumBackward0>),\n",
       "  tensor(1.7333, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.5191, grad_fn=<SumBackward0>),\n",
       "  tensor(4.2049, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.2049, grad_fn=<SumBackward0>),\n",
       "  tensor(4.5191, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.2258, grad_fn=<SumBackward0>),\n",
       "  tensor(4.4615, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.7828, grad_fn=<SumBackward0>),\n",
       "  tensor(3.5694, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.4622, grad_fn=<SumBackward0>),\n",
       "  tensor(3.6560, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.4259, grad_fn=<SumBackward0>),\n",
       "  tensor(3.4189, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.6443, grad_fn=<SumBackward0>),\n",
       "  tensor(3.8014, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.8014, grad_fn=<SumBackward0>),\n",
       "  tensor(4.6443, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.3198, grad_fn=<SumBackward0>),\n",
       "  tensor(4.3198, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.5029, grad_fn=<SumBackward0>),\n",
       "  tensor(4.5029, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.5699, grad_fn=<SumBackward0>),\n",
       "  tensor(3.3218, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.1651, grad_fn=<SumBackward0>),\n",
       "  tensor(3.3866, grad_fn=<SumBackward0>)),\n",
       " (tensor(2.5026, grad_fn=<SumBackward0>),\n",
       "  tensor(2.9178, grad_fn=<SumBackward0>)),\n",
       " (tensor(1.9834, grad_fn=<SumBackward0>),\n",
       "  tensor(1.5501, grad_fn=<SumBackward0>)),\n",
       " (tensor(1.2122, grad_fn=<SumBackward0>),\n",
       "  tensor(1.2122, grad_fn=<SumBackward0>)),\n",
       " (tensor(1.3564, grad_fn=<SumBackward0>),\n",
       "  tensor(1.6531, grad_fn=<SumBackward0>)),\n",
       " (tensor(2.7896, grad_fn=<SumBackward0>),\n",
       "  tensor(3.2455, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.2455, grad_fn=<SumBackward0>),\n",
       "  tensor(2.7896, grad_fn=<SumBackward0>)),\n",
       " (tensor(1.7542, grad_fn=<SumBackward0>),\n",
       "  tensor(1.7542, grad_fn=<SumBackward0>)),\n",
       " (tensor(1.5844, grad_fn=<SumBackward0>),\n",
       "  tensor(1.5844, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.8967, grad_fn=<SumBackward0>),\n",
       "  tensor(3.8967, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.8800, grad_fn=<SumBackward0>),\n",
       "  tensor(3.8800, grad_fn=<SumBackward0>)),\n",
       " (tensor(2.3178, grad_fn=<SumBackward0>),\n",
       "  tensor(2.3178, grad_fn=<SumBackward0>)),\n",
       " (tensor(2.5913, grad_fn=<SumBackward0>),\n",
       "  tensor(2.5913, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.9138, grad_fn=<SumBackward0>),\n",
       "  tensor(4.8633, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.8633, grad_fn=<SumBackward0>),\n",
       "  tensor(4.9138, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.1650, grad_fn=<SumBackward0>),\n",
       "  tensor(3.7249, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.7249, grad_fn=<SumBackward0>),\n",
       "  tensor(4.1650, grad_fn=<SumBackward0>)),\n",
       " (tensor(2.0503, grad_fn=<SumBackward0>),\n",
       "  tensor(2.0503, grad_fn=<SumBackward0>)),\n",
       " (tensor(2.7457, grad_fn=<SumBackward0>),\n",
       "  tensor(2.7457, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.2610, grad_fn=<SumBackward0>),\n",
       "  tensor(3.2610, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.4855, grad_fn=<SumBackward0>),\n",
       "  tensor(3.4855, grad_fn=<SumBackward0>)),\n",
       " (tensor(6.3806, grad_fn=<SumBackward0>),\n",
       "  tensor(6.4218, grad_fn=<SumBackward0>)),\n",
       " (tensor(6.4218, grad_fn=<SumBackward0>),\n",
       "  tensor(6.3806, grad_fn=<SumBackward0>)),\n",
       " (tensor(6.1635, grad_fn=<SumBackward0>),\n",
       "  tensor(5.1724, grad_fn=<SumBackward0>)),\n",
       " (tensor(5.3873, grad_fn=<SumBackward0>),\n",
       "  tensor(6.3627, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.1589, grad_fn=<SumBackward0>),\n",
       "  tensor(3.0771, grad_fn=<SumBackward0>)),\n",
       " (tensor(2.7776, grad_fn=<SumBackward0>),\n",
       "  tensor(2.7228, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.9544, grad_fn=<SumBackward0>),\n",
       "  tensor(4.4086, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.4822, grad_fn=<SumBackward0>),\n",
       "  tensor(4.1860, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.2446, grad_fn=<SumBackward0>),\n",
       "  tensor(4.7784, grad_fn=<SumBackward0>)),\n",
       " (tensor(2.0355, grad_fn=<SumBackward0>),\n",
       "  tensor(1.6865, grad_fn=<SumBackward0>)),\n",
       " (tensor(1.8397, grad_fn=<SumBackward0>),\n",
       "  tensor(1.9874, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.9843, grad_fn=<SumBackward0>),\n",
       "  tensor(3.9843, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.4986, grad_fn=<SumBackward0>),\n",
       "  tensor(4.4986, grad_fn=<SumBackward0>)),\n",
       " (tensor(2.1967, grad_fn=<SumBackward0>),\n",
       "  tensor(1.9062, grad_fn=<SumBackward0>)),\n",
       " (tensor(1.8640, grad_fn=<SumBackward0>),\n",
       "  tensor(2.0825, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.7534, grad_fn=<SumBackward0>),\n",
       "  tensor(3.9404, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.0331, grad_fn=<SumBackward0>),\n",
       "  tensor(2.8781, grad_fn=<SumBackward0>)),\n",
       " (tensor(2.3601, grad_fn=<SumBackward0>),\n",
       "  tensor(1.3885, grad_fn=<SumBackward0>)),\n",
       " (tensor(1.4995, grad_fn=<SumBackward0>),\n",
       "  tensor(2.4705, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.1617, grad_fn=<SumBackward0>),\n",
       "  tensor(4.9080, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.0666, grad_fn=<SumBackward0>),\n",
       "  tensor(3.9427, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.5123, grad_fn=<SumBackward0>),\n",
       "  tensor(3.4528, grad_fn=<SumBackward0>)),\n",
       " (tensor(2.8554, grad_fn=<SumBackward0>),\n",
       "  tensor(2.9911, grad_fn=<SumBackward0>)),\n",
       " (tensor(6.1492, grad_fn=<SumBackward0>),\n",
       "  tensor(6.1492, grad_fn=<SumBackward0>)),\n",
       " (tensor(6.1492, grad_fn=<SumBackward0>),\n",
       "  tensor(6.1492, grad_fn=<SumBackward0>)),\n",
       " (tensor(5.8988, grad_fn=<SumBackward0>),\n",
       "  tensor(5.8988, grad_fn=<SumBackward0>)),\n",
       " (tensor(5.8988, grad_fn=<SumBackward0>),\n",
       "  tensor(5.8988, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.5290, grad_fn=<SumBackward0>),\n",
       "  tensor(4.8387, grad_fn=<SumBackward0>)),\n",
       " (tensor(4.9560, grad_fn=<SumBackward0>),\n",
       "  tensor(4.9389, grad_fn=<SumBackward0>)),\n",
       " (tensor(2.5928, grad_fn=<SumBackward0>),\n",
       "  tensor(2.8366, grad_fn=<SumBackward0>)),\n",
       " (tensor(3.8579, grad_fn=<SumBackward0>),\n",
       "  tensor(3.2518, grad_fn=<SumBackward0>)),\n",
       " (tensor(7.2003, grad_fn=<SumBackward0>),\n",
       "  tensor(7.1457, grad_fn=<SumBackward0>)),\n",
       " (tensor(7.1457, grad_fn=<SumBackward0>),\n",
       "  tensor(7.2003, grad_fn=<SumBackward0>)),\n",
       " (tensor(7.2548, grad_fn=<SumBackward0>),\n",
       "  tensor(9.0380, grad_fn=<SumBackward0>))]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c5c53e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
